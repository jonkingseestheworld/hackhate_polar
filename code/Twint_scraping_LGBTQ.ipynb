{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 17470,
     "status": "ok",
     "timestamp": 1603706549445,
     "user": {
      "displayName": "Piera Carugno",
      "photoUrl": "",
      "userId": "12160015843414474967"
     },
     "user_tz": 0
    },
    "id": "pLV6CvNeJh1A",
    "outputId": "f67d35dd-2af3-4598-a674-5fa660d3225a"
   },
   "outputs": [],
   "source": [
    "# pip install twint module from its repo\n",
    "#!pip3 install --user --upgrade git+https://github.com/twintproject/twint.git@origin/master#egg=twint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "executionInfo": {
     "elapsed": 3582,
     "status": "ok",
     "timestamp": 1603706691868,
     "user": {
      "displayName": "Piera Carugno",
      "photoUrl": "",
      "userId": "12160015843414474967"
     },
     "user_tz": 0
    },
    "id": "y4Mj5wLJ442_",
    "outputId": "fef576f8-b875-4a81-c289-9d5b412d3687"
   },
   "outputs": [],
   "source": [
    "## There are known issues running twint in jupyter, nest_asyncio may be able to solve the problem. \n",
    "## When in an environment where the event loop is already running itâ€™s impossible to run tasks and wait for the result.\n",
    "## nest_asyncio may solve this problem\n",
    " \n",
    "#!pip install nest_asyncio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "executionInfo": {
     "elapsed": 23256,
     "status": "ok",
     "timestamp": 1603706720301,
     "user": {
      "displayName": "Piera Carugno",
      "photoUrl": "",
      "userId": "12160015843414474967"
     },
     "user_tz": 0
    },
    "id": "zuy9Sr2O5CuW",
    "outputId": "04d1fdd6-7664-4f9e-f406-6f2689500adb"
   },
   "outputs": [],
   "source": [
    "# If working on google.colab, these code would be useful for mounting to your own google drive. \n",
    "# Otherwise, anything that is saved within Google Colab environment will be deleted at the end of each session\n",
    "\n",
    "#from google.colab import drive\n",
    "#drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 2831,
     "status": "ok",
     "timestamp": 1603706747241,
     "user": {
      "displayName": "Piera Carugno",
      "photoUrl": "",
      "userId": "12160015843414474967"
     },
     "user_tz": 0
    },
    "id": "7HXpn38U5E2_"
   },
   "outputs": [],
   "source": [
    "#scientific and machine learning libraries\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix,f1_score\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "#plotting options\n",
    "import seaborn as sns\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import missingno as ms\n",
    "#% matplotlib inline\n",
    "pd.set_option('display.max_colwidth',None)\n",
    "import seaborn as sns\n",
    "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n",
    "#twint\n",
    "import twint\n",
    "#to avoid problems with running twint\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 3703,
     "status": "ok",
     "timestamp": 1603706769658,
     "user": {
      "displayName": "Piera Carugno",
      "photoUrl": "",
      "userId": "12160015843414474967"
     },
     "user_tz": 0
    },
    "id": "B-vofqyc5L0F"
   },
   "outputs": [],
   "source": [
    "## Sources: \n",
    "\n",
    "lgbtqia_basic = [\"UK asexual\", \"UK bisexual OR UK bisex OR UK bi-sexual\", \"UK drag\",\"UK dyke\", \"UK faggot\",\n",
    "                 \"UK gay\", \"UK gender\",\"UK genderfluid\",\"UK homophobia OR UK homophobic\",\"UK intersex\", \"UK lesbo\", \"UK lesbian\", \n",
    "                 \"UK non-binary OR UK nonbinary\",\"UK omnigender\",\"UK pansexual\",\"UK polysexual\", \n",
    "                 \"UK pride\", \"UK queer\", \"UK sogie\", \"UK trans\",\"UK unisexual\", \"UK ursula\", \"UK transphobic\"]\n",
    "\n",
    "search_concatenation = lgbtqia_basic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_concatenation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(search_concatenation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-MxUEQxVWC86",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# the concept is to perform the scraping using the elements in the lists above: imm_basic, immigrant_mod, migrant_mod and refugee_mod\n",
    "appended_data = []\n",
    "for s in search_concatenation:\n",
    "    config = twint.Config()\n",
    "    config.Search = s\n",
    "    config.Lang = \"en\"\n",
    "    config.Limit = 300000\n",
    "    config.Since = \"2015-10-01 00:00:00\"\n",
    "    config.Until = \"2016-10-01 00:00:00\"\n",
    "    config.Hide_output = True\n",
    "    config.Pandas = True\n",
    "    twint.run.Search(config)\n",
    "    Tweets_df = twint.storage.panda.Tweets_df\n",
    "    appended_data.append(Tweets_df)  \n",
    "    \n",
    "# see pd.concat documentation for more info\n",
    "appended_data = pd.concat(appended_data).sort_values(by=['date']).reset_index()\n",
    "\n",
    "print(len(appended_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "appended_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with this command I'm checking \n",
    "\n",
    "appended_data.groupby('search').sum().shape, len(search_concatenation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "appended_data.to_csv('../data/lgbtq_df_2015_2016.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Twint_scraping_immigration.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

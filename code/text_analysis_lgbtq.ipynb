{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining modules/packages to import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import spacy\n",
    "\n",
    "# importing package to recognize stop words i.e. the, and, an etc\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "stop_words = spacy.lang.en.stop_words.STOP_WORDS\n",
    "\n",
    "import datetime\n",
    "\n",
    "import plotly.express as px\n",
    "\n",
    "#nltk.download('punkt')\n",
    "stop_words = spacy.lang.en.stop_words.STOP_WORDS\n",
    "\n",
    "stemmer = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing module to ignore the warnings\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining functions to be used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Now creating some functions to do text processing\n",
    "# Removing hashtags and mentions\n",
    "def get_hashtags(text):\n",
    "    hashtags = re.findall(r'\\#\\w+',text.lower())\n",
    "    return hashtags\n",
    "def get_mentions(text):\n",
    "    mentions = re.findall(r'\\@\\w+',text.lower())\n",
    "    return mentions\n",
    "\n",
    "# Cleaning up the text of the tweets\n",
    "def remove_content(text):\n",
    "    text = re.sub(r\"http\\S+\", \"\", text) #remove urls\n",
    "    text=re.sub(r'\\S+\\.com\\S+','',text) #remove urls\n",
    "    text=re.sub(r'\\@\\w+','',text) #remove mentions\n",
    "    text =re.sub(r'\\#\\w+','',text) #remove hashtags\n",
    "    return text\n",
    "\n",
    "def process_tweet(tweet):\n",
    "    \"\"\" \n",
    "    tweets cleaning by \n",
    "    1) lowering the case of the tweet, \n",
    "    2) removing unwanted symbols and replacing them with a whitespace, \n",
    "    3) split sentences into words according to whitespaces and then \n",
    "    4) join back with a single whitespace as separator between various words\n",
    "    \"\"\"\n",
    "    return \" \".join(re.sub(\"(@[A-Za-z0-9]+)|([^0-9A-Za-z \\t])\", \" \",tweet.lower()).split())\n",
    "\n",
    "def process_text(text, stem=False): #clean text\n",
    "    text=remove_content(text)\n",
    "    lemmatizer=WordNetLemmatizer()\n",
    "    text = re.sub('[^A-Za-z]', ' ', text.lower()) #remove non-alphabets\n",
    "    text = re.sub(r\"\\bamp\\b\", ' ', text.lower()) #remove \"amp\" which is coming from the translation of &\n",
    "    text = re.sub(r\"\\bco\\b\", ' ', text.lower()) #remove \"co\" which was one of the top words found below\n",
    "    tokenized_text = word_tokenize(text) #tokenize\n",
    "    #tokenized_text = [lemmatizer.lemmatize(word) for word in tokenized_text]\n",
    "    clean_text = [\n",
    "         word for word in tokenized_text\n",
    "         if (word not in stop_words and len(word)>1)\n",
    "    ]\n",
    "    if stem:\n",
    "        clean_text=[stemmer.stem(word) for word in clean_text]\n",
    "    clean_text = [lemmatizer.lemmatize(word) for word in clean_text]\n",
    "    return ' '.join(clean_text)\n",
    "\n",
    "#functions used to remove search terms from all the tweets\n",
    "#function to remove duplicates from a string - in this case the string is the keywords used to scrape the tweets\n",
    "def removeDupWithoutOrder(string): \n",
    "    words = string.lower().split()\n",
    "    return \" \".join(sorted(set(words), key=words.index)).replace('OR', '').replace('  ', ' ')\n",
    "\n",
    "#function to search for string (i.e. tweet in this case) and remove specific words (search_terms in this case)\n",
    "def remove_search(text, search_terms):\n",
    "    query = text.lower()\n",
    "    querywords = query.split()\n",
    "    resultwords  = [word for word in querywords if word.lower() not in search_terms]\n",
    "    return ' '.join(resultwords)\n",
    "\n",
    "# define function to plot frequency of bi-grams, tri-grams, single words, phrases etc\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "def plot_topn(sentences, ngram_range=(1,3), top=20,firstword=''):\n",
    "    c=CountVectorizer(ngram_range=ngram_range)\n",
    "    X=c.fit_transform(sentences)\n",
    "    words=pd.DataFrame(X.sum(axis=0),columns=c.get_feature_names()).T.sort_values(0,ascending=False).reset_index()\n",
    "    res=words[words['index'].apply(lambda x: firstword in x)].head(top)\n",
    "    pl=px.bar(res, x='index',y=0)\n",
    "    pl.update_layout(yaxis_title='count',xaxis_title='Phrases')\n",
    "    pl.show('png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Search terms used to do tweet scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords = [\"UK asexual\", \"UK bisexual OR UK bisex OR UK bi-sexual\", \"UK drag\",\"UK dyke\", \"UK faggot\",\n",
    "                 \"UK gay\", \"UK gender\",\"UK genderfluid\",\"UK homophobia OR UK homophobic\",\"UK intersex\", \"UK lesbo\", \"UK lesbian\", \n",
    "                 \"UK non-binary OR UK nonbinary\",\"UK omnigender\",\"UK pansexual\",\"UK polysexual\", \n",
    "                 \"UK pride\", \"UK queer\", \"UK sogie\", \"UK trans\",\"UK unisexual\", \"UK ursula\", \"UK transphobic\"]\n",
    "keywords_concat = ' '.join(keywords)\n",
    "\n",
    "search_concatenation = keywords_concat\n",
    "# now creating a string with unique occurrences of words from \"search_concatenation\"\n",
    "search_concat_unique = removeDupWithoutOrder(search_concatenation).lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'uk asexual bisexual or bisex bi-sexual drag dyke faggot gay gender genderfluid homophobia homophobic intersex lesbo lesbian non-binary nonbinary omnigender pansexual polysexual pride queer sogie trans unisexual ursula transphobic'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_concat_unique"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now importing database to do analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing scraped database and putting it in df, taking only the columns below\n",
    "df=pd.read_csv('../data/lgbtq_df_2019_2020.csv')[['date','tweet','nlikes','nreplies','nretweets']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# taking the 'date' column (which is a string) and extracting date, times, breaking it down in months, years etc\n",
    "\n",
    "df['INCDTTM'] =  pd.to_datetime(df['date'], infer_datetime_format=True)\n",
    "df['Time'] = [datetime.datetime.time(d) for d in df['INCDTTM']] \n",
    "df['Date'] = [datetime.datetime.date(d) for d in df['INCDTTM']]\n",
    "df['Year'] = [datetime.datetime.date(d).year for d in df['INCDTTM']] \n",
    "df['Month'] = [datetime.datetime.date(d).month for d in df['INCDTTM']] \n",
    "df['Day'] = [datetime.datetime.date(d).day for d in df['INCDTTM']] \n",
    "df['Hours'] = [datetime.datetime.time(d).hour for d in df['INCDTTM']] \n",
    "df['Minutes'] = [datetime.datetime.time(d).minute for d in df['INCDTTM']] \n",
    "df['Seconds'] = [datetime.datetime.time(d).second for d in df['INCDTTM']]\n",
    "df = df.drop(columns = ['date','INCDTTM'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing useless content (hashtags, mentions)\n",
    "df['tweet']=df['tweet'].apply(lambda x: remove_content(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Several functions applied here: processing the *tweet* to remove punctuation, hashtags, mentions\n",
    "# then removing the search terms used to do the tweets scraping and re-process the *text* \n",
    "\n",
    "df['cleaned_tweets']=df['tweet'].apply(lambda x: process_tweet(x))\n",
    "\n",
    "#this next row drops from the scraped tweets the same keywords that were used to perform the search.\n",
    "#if these words are excluded, the sentiment analysis performed with text blob looks at the whole tweet \n",
    "#and can spit out a different sentiment wrt if leaving the search terms in. Perhaps worth test it out a bit\n",
    "#and look at TextBlob with naivebayes too.\n",
    "\n",
    "#df['cleaned_tweets']=df['cleaned_tweets'].apply(lambda x: remove_search(x, search_concat_unique))\n",
    "\n",
    "df['cleaned_tweets']=df['cleaned_tweets'].apply(lambda x: process_text(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# taking the cleaning tweets and dividing them using the space - cleaned tweets contain tweets that are stemmed and cleaned\n",
    "tweet_list = df['cleaned_tweets'].tolist()\n",
    "all_words=' '.join(tweet_list).split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_topn(tweet_list, ngram_range=(1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_topn(tweet_list, ngram_range=(2,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_topn(tweet_list, ngram_range=(3,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wordcloud of most used words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud, STOPWORDS\n",
    "temp=' '.join(df['cleaned_tweets'].tolist())\n",
    "wordcloud = WordCloud(width = 800, height = 500, \n",
    "                background_color ='white',\n",
    "                min_font_size = 10).generate(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize = (8, 8), facecolor = None) \n",
    "plt.imshow(wordcloud) \n",
    "plt.axis(\"off\")\n",
    "plt.tight_layout(pad = 0) \n",
    "  \n",
    "plt.show('png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob \n",
    "\n",
    "def get_tweet_sentiment(tweet): \n",
    "        ''' \n",
    "        Utility function to classify sentiment of passed tweet \n",
    "        using textblob's sentiment method \n",
    "        '''\n",
    "        # create TextBlob object of passed tweet text \n",
    "        analysis = TextBlob(tweet) \n",
    "        # set sentiment \n",
    "        if analysis.sentiment.polarity > 0: \n",
    "            return 'positive'\n",
    "        elif analysis.sentiment.polarity == 0: \n",
    "            return 'neutral'\n",
    "        else: \n",
    "            return 'negative'    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['sentiment']=df['cleaned_tweets'].apply(lambda x: get_tweet_sentiment(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sentiment.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Positive']= df['sentiment'].apply(lambda x: 1 if (x==\"positive\")  else 0)\n",
    "df['Negative']= df['sentiment'].apply(lambda x: 1 if (x==\"negative\")  else 0)\n",
    "df['Neutral']= df['sentiment'].apply(lambda x: 1 if (x==\"neutral\")  else 0)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_timeline = df.groupby(df.Date).sum().reset_index()\n",
    "df_timeline['Total'] = df_timeline.Positive + df_timeline.Negative + df_timeline.Neutral\n",
    "df_timeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "t = np.arange(df_timeline.Date[0], df_timeline.Date[365], timedelta(days=7)).astype(datetime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.figure(figsize=(20,5))\n",
    "#plt.bar(df_timeline.Date, (df_timeline['Positive']/df_timeline['Total']));\n",
    "#plt.bar(df_timeline.Date, (df_timeline['Negative']/df_timeline['Total']), bottom = (df_timeline['Positive']/df_timeline['Total']));\n",
    "#plt.legend(['Positive', 'Negative']);\n",
    "#plt.xticks(t, rotation='vertical');\n",
    "#plt.ylabel('Number of positive and negative tweets');\n",
    "#plt.xlabel('Date');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "fig = go.Figure()\n",
    "fig.add_bar(x=df_timeline.Date, y=100*df_timeline.Negative/(df_timeline.Total), name=\"% Negative\")\n",
    "fig.add_bar(x=df_timeline.Date, y=100*df_timeline.Positive/(df_timeline.Total), name=\"% Positive\")\n",
    "fig.add_bar(x=df_timeline.Date, y=100*df_timeline.Neutral/df_timeline.Total, name=\"% Neutral\")\n",
    "fig.add_trace(go.Scatter(x=[df_timeline.Date[0], df_timeline.Date[365]],y=[50,50],name=\"50% threshold\"))\n",
    "fig.update_layout(barmode=\"relative\")\n",
    "fig.update_layout(showlegend=True,title=\"Tweets split by sentiment: % positive, % negative and % neutral\",\n",
    "                 yaxis_title=\"% of total tweets\", xaxis_title=\"Time\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some further analyses on percentages of positive/negative/neutral tweets and saving them locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new = df_timeline[['Date', 'Negative','Positive','Neutral','Total']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new['Percentage_neg'] = 100*(df_new.Negative/df_new.Total)\n",
    "df_new['Percentage_pos'] = 100*(df_new.Positive/df_new.Total)\n",
    "df_new['Percentage_neutr'] = 100*(df_new.Neutral/df_new.Total)\n",
    "df_new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_new.to_csv('../data/lgbtq_2019_2020_postprocessed.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now we turn our attention to the reactions and engagements - by categories: likes, replies, retweets. What is making more 'noise'? Negative or positive tweets?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reactions_vert = pd.DataFrame(columns=['Date', 'Positive_nlikes', 'Positive_nreplies', 'Positive_nretweets', 'Negative_nlikes', 'Negative_nreplies', 'Negative_nretweets', 'Neutral_nlikes', 'Neutral_nreplies', 'Neutral_nretweets', 'Total_nlikes', 'Total_nreplies', 'Total_nretweets'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reactions_vert.Date = df.loc[df['Positive'] == 1].groupby(df.Date).sum().reset_index().Date\n",
    "reactions_vert.Positive_nlikes = df.loc[df['Positive'] == 1].groupby(df.Date).sum().reset_index().nlikes\n",
    "reactions_vert.Positive_nreplies = df.loc[df['Positive'] == 1].groupby(df.Date).sum().reset_index().nreplies\n",
    "reactions_vert.Positive_nretweets = df.loc[df['Positive'] == 1].groupby(df.Date).sum().reset_index().nretweets\n",
    "\n",
    "reactions_vert.Negative_nlikes = df.loc[df['Negative'] == 1].groupby(df.Date).sum().reset_index().nlikes\n",
    "reactions_vert.Negative_nreplies = df.loc[df['Negative'] == 1].groupby(df.Date).sum().reset_index().nreplies\n",
    "reactions_vert.Negative_nretweets = df.loc[df['Negative'] == 1].groupby(df.Date).sum().reset_index().nretweets\n",
    "\n",
    "reactions_vert.Neutral_nlikes = df.loc[df['Neutral'] == 1].groupby(df.Date).sum().reset_index().nlikes\n",
    "reactions_vert.Neutral_nreplies = df.loc[df['Neutral'] == 1].groupby(df.Date).sum().reset_index().nreplies\n",
    "reactions_vert.Neutral_nretweets = df.loc[df['Neutral'] == 1].groupby(df.Date).sum().reset_index().nretweets\n",
    "\n",
    "#cumulative total of likes, replies and retweets per day\n",
    "\n",
    "reactions_vert.Total_nlikes = reactions_vert.Positive_nlikes + reactions_vert.Negative_nlikes + reactions_vert.Neutral_nlikes\n",
    "reactions_vert.Total_nreplies = reactions_vert.Positive_nreplies + reactions_vert.Negative_nreplies + reactions_vert.Neutral_nreplies\n",
    "reactions_vert.Total_nretweets = reactions_vert.Positive_nretweets + reactions_vert.Negative_nretweets + reactions_vert.Neutral_nretweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reactions_vert.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reactions_vert.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reactions_vert.to_csv('../data/lgbtq_2019_2020_reactions_vert.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reactions_perc_v = pd.DataFrame(columns=['Date', 'Positive_nlikes', 'Positive_nreplies', 'Positive_nretweets', 'Negative_nlikes', 'Negative_nreplies', 'Negative_nretweets', 'Neutral_nlikes', 'Neutral_nreplies', 'Neutral_nretweets'])\n",
    "\n",
    "reactions_perc_v.Date = reactions_vert.Date\n",
    "\n",
    "# Now defining percentages of each reaction (like or reply or retweet) wrt to their total across sentiment. \n",
    "# By doing so we're calculating how each reaction is split by **sentiment** \n",
    "\n",
    "reactions_perc_v.Positive_nlikes = 100*reactions_vert.Positive_nlikes/reactions_vert.Total_nlikes\n",
    "reactions_perc_v.Positive_nreplies = 100*reactions_vert.Positive_nreplies/reactions_vert.Total_nreplies\n",
    "reactions_perc_v.Positive_nretweets = 100*reactions_vert.Positive_nretweets/reactions_vert.Total_nretweets\n",
    "\n",
    "reactions_perc_v.Negative_nlikes = 100*reactions_vert.Negative_nlikes/reactions_vert.Total_nlikes\n",
    "reactions_perc_v.Negative_nreplies = 100*reactions_vert.Negative_nreplies/reactions_vert.Total_nreplies\n",
    "reactions_perc_v.Negative_nretweets = 100*reactions_vert.Negative_nretweets/reactions_vert.Total_nretweets\n",
    "\n",
    "reactions_perc_v.Neutral_nlikes = 100*reactions_vert.Neutral_nlikes/reactions_vert.Total_nlikes\n",
    "reactions_perc_v.Neutral_nreplies = 100*reactions_vert.Neutral_nreplies/reactions_vert.Total_nreplies\n",
    "reactions_perc_v.Neutral_nretweets = 100*reactions_vert.Neutral_nretweets/reactions_vert.Total_nretweets\n",
    "\n",
    "reactions_perc_v['Positive tweets'] = 100*df_timeline.Positive/df_timeline.Total\n",
    "reactions_perc_v['Negative tweets'] = 100*df_timeline.Negative/df_timeline.Total\n",
    "reactions_perc_v['Neutral tweets'] = 100*df_timeline.Neutral/df_timeline.Total\n",
    "\n",
    "reactions_perc_v.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reactions_perc_v.to_csv('../data/lgbtq_2019_2020_reactions_perc_v.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plots showing for each type of reactions, what's the split by sentiment - first by % then by absolute numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plotly.subplots import make_subplots\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "fig = make_subplots(rows=1, cols=1)\n",
    "fig.add_bar(x=reactions_perc_v.Date, y=reactions_perc_v.Positive_nlikes, name=\"% Positive\", row=1, col=1)\n",
    "fig.add_bar(x=reactions_perc_v.Date, y=reactions_perc_v.Negative_nlikes, name=\"% Negative\", row=1, col=1)\n",
    "fig.add_bar(x=reactions_perc_v.Date, y=reactions_perc_v.Neutral_nlikes, name=\"% Neutral\", row=1, col=1)\n",
    "fig.update_layout(barmode=\"relative\",showlegend=True,title=\"'Likes' split by sentiment\",\n",
    "                 yaxis_title=\"% of likes\", xaxis_title=\"Time\")\n",
    "fig.show()\n",
    "\n",
    "fig = make_subplots(rows=1, cols=1)\n",
    "fig.add_bar(x=reactions_perc_v.Date, y=reactions_perc_v.Positive_nreplies, name=\"% Positive\", row=1, col=1)\n",
    "fig.add_bar(x=reactions_perc_v.Date, y=reactions_perc_v.Negative_nreplies, name=\"% Negative\", row=1, col=1)\n",
    "fig.add_bar(x=reactions_perc_v.Date, y=reactions_perc_v.Neutral_nreplies, name=\"% Neutral\", row=1, col=1)\n",
    "fig.update_layout(barmode=\"relative\",showlegend=True,title=\"'Replies' split by sentiment\",\n",
    "                 yaxis_title=\"% of replies\", xaxis_title=\"Time\")\n",
    "fig.show()\n",
    "\n",
    "fig = make_subplots(rows=1, cols=1)\n",
    "fig.add_bar(x=reactions_perc_v.Date, y=reactions_perc_v.Positive_nretweets, name=\"% Positive\", row=1, col=1)\n",
    "fig.add_bar(x=reactions_perc_v.Date, y=reactions_perc_v.Negative_nretweets, name=\"% Negative\", row=1, col=1)\n",
    "fig.add_bar(x=reactions_perc_v.Date, y=reactions_perc_v.Neutral_nretweets, name=\"% Neutral\", row=1, col=1)\n",
    "fig.update_layout(barmode=\"relative\",showlegend=True,title=\"'Retweets' split by sentiment\",\n",
    "                 yaxis_title=\"% of retweets\", xaxis_title=\"Time\")\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plotly.subplots import make_subplots\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "fig = make_subplots(rows=1, cols=1)\n",
    "fig.add_bar(x=reactions_vert.Date, y=reactions_vert.Positive_nlikes, name=\"Positive\", row=1, col=1)\n",
    "fig.add_bar(x=reactions_vert.Date, y=reactions_vert.Negative_nlikes, name=\"Negative\", row=1, col=1)\n",
    "fig.add_bar(x=reactions_vert.Date, y=reactions_vert.Neutral_nlikes, name=\"Neutral\", row=1, col=1)\n",
    "fig.update_layout(barmode=\"relative\",showlegend=True,title=\"'Likes' split by sentiment\",\n",
    "                 yaxis_title=\"Number of likes\", xaxis_title=\"Time\")\n",
    "fig.show()\n",
    "\n",
    "fig = make_subplots(rows=1, cols=1)\n",
    "fig.add_bar(x=reactions_vert.Date, y=reactions_vert.Positive_nreplies, name=\"Positive\", row=1, col=1)\n",
    "fig.add_bar(x=reactions_vert.Date, y=reactions_vert.Negative_nreplies, name=\"Negative\", row=1, col=1)\n",
    "fig.add_bar(x=reactions_vert.Date, y=reactions_vert.Neutral_nreplies, name=\"Neutral\", row=1, col=1)\n",
    "fig.update_layout(barmode=\"relative\",showlegend=True,title=\"'Replies' split by sentiment\",\n",
    "                 yaxis_title=\"Number of replies\", xaxis_title=\"Time\")\n",
    "fig.show()\n",
    "\n",
    "fig = make_subplots(rows=1, cols=1)\n",
    "fig.add_bar(x=reactions_vert.Date, y=reactions_vert.Positive_nretweets, name=\"Positive\", row=1, col=1)\n",
    "fig.add_bar(x=reactions_vert.Date, y=reactions_vert.Negative_nretweets, name=\"Negative\", row=1, col=1)\n",
    "fig.add_bar(x=reactions_vert.Date, y=reactions_vert.Neutral_nretweets, name=\"Neutral\", row=1, col=1)\n",
    "fig.update_layout(barmode=\"relative\",showlegend=True,title=\"'Retweets' split by sentiment\",\n",
    "                 yaxis_title=\"Number of retweets\", xaxis_title=\"Time\")\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we create a new dataframe to illustrate how each sentiment is split by reaction\n",
    "\n",
    "reactions_hor = pd.DataFrame(columns=['Date', 'Positive_nlikes', 'Positive_nreplies', 'Positive_nretweets', 'Negative_nlikes', 'Negative_nreplies', \n",
    "                                  'Negative_nretweets', 'Neutral_nlikes', 'Neutral_nreplies', 'Neutral_nretweets', \n",
    "                                  'Total_Positive', 'Total_Negative', 'Total_Neutral'])\n",
    "\n",
    "reactions_hor.Date = df.loc[df['Positive'] == 1].groupby(df.Date).sum().reset_index().Date\n",
    "reactions_hor.Positive_nlikes = df.loc[df['Positive'] == 1].groupby(df.Date).sum().reset_index().nlikes\n",
    "reactions_hor.Positive_nreplies = df.loc[df['Positive'] == 1].groupby(df.Date).sum().reset_index().nreplies\n",
    "reactions_hor.Positive_nretweets = df.loc[df['Positive'] == 1].groupby(df.Date).sum().reset_index().nretweets\n",
    "\n",
    "reactions_hor.Negative_nlikes = df.loc[df['Negative'] == 1].groupby(df.Date).sum().reset_index().nlikes\n",
    "reactions_hor.Negative_nreplies = df.loc[df['Negative'] == 1].groupby(df.Date).sum().reset_index().nreplies\n",
    "reactions_hor.Negative_nretweets = df.loc[df['Negative'] == 1].groupby(df.Date).sum().reset_index().nretweets\n",
    "\n",
    "reactions_hor.Neutral_nlikes = df.loc[df['Neutral'] == 1].groupby(df.Date).sum().reset_index().nlikes\n",
    "reactions_hor.Neutral_nreplies = df.loc[df['Neutral'] == 1].groupby(df.Date).sum().reset_index().nreplies\n",
    "reactions_hor.Neutral_nretweets = df.loc[df['Neutral'] == 1].groupby(df.Date).sum().reset_index().nretweets\n",
    "\n",
    "#cumulative total of (likes+replies+retweets) per day by sentiment\n",
    "\n",
    "reactions_hor.Total_Positive = reactions_hor.Positive_nlikes + reactions_hor.Positive_nreplies + reactions_hor.Positive_nretweets\n",
    "reactions_hor.Total_Negative = reactions_hor.Negative_nlikes + reactions_hor.Negative_nreplies + reactions_hor.Negative_nretweets\n",
    "reactions_hor.Total_Neutral = reactions_hor.Neutral_nlikes + reactions_hor.Neutral_nreplies + reactions_hor.Neutral_nretweets\n",
    "\n",
    "reactions_hor.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reactions_hor.to_csv('../data/lgbtq_2019_2020_reactions_hor.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reactions_perc_h = pd.DataFrame(columns=['Date', 'Positive_nlikes', 'Positive_nreplies', 'Positive_nretweets', \n",
    "                                         'Negative_nlikes', 'Negative_nreplies', 'Negative_nretweets', \n",
    "                                         'Neutral_nlikes', 'Neutral_nreplies', 'Neutral_nretweets'])\n",
    "\n",
    "reactions_perc_h.Date = reactions_hor.Date\n",
    "\n",
    "# Now defining percentages of each reaction (like or reply or retweet) wrt to their total across sentiment. \n",
    "# By doing so we're calculating how each reaction is split by **sentiment** \n",
    "\n",
    "reactions_perc_h.Positive_nlikes = 100*reactions_hor.Positive_nlikes/reactions_hor.Total_Positive\n",
    "reactions_perc_h.Positive_nreplies = 100*reactions_hor.Positive_nreplies/reactions_hor.Total_Positive\n",
    "reactions_perc_h.Positive_nretweets = 100*reactions_hor.Positive_nretweets/reactions_hor.Total_Positive\n",
    "\n",
    "reactions_perc_h.Negative_nlikes = 100*reactions_hor.Negative_nlikes/reactions_hor.Total_Negative\n",
    "reactions_perc_h.Negative_nreplies = 100*reactions_hor.Negative_nreplies/reactions_hor.Total_Negative\n",
    "reactions_perc_h.Negative_nretweets = 100*reactions_hor.Negative_nretweets/reactions_hor.Total_Negative\n",
    "\n",
    "reactions_perc_h.Neutral_nlikes = 100*reactions_hor.Neutral_nlikes/reactions_hor.Total_Neutral\n",
    "reactions_perc_h.Neutral_nreplies = 100*reactions_hor.Neutral_nreplies/reactions_hor.Total_Neutral\n",
    "reactions_perc_h.Neutral_nretweets = 100*reactions_hor.Neutral_nretweets/reactions_hor.Total_Neutral\n",
    "\n",
    "reactions_perc_h['Positive tweets'] = 100*df_timeline.Positive/df_timeline.Total\n",
    "reactions_perc_h['Negative tweets'] = 100*df_timeline.Negative/df_timeline.Total\n",
    "reactions_perc_h['Neutral tweets'] = 100*df_timeline.Neutral/df_timeline.Total\n",
    "\n",
    "reactions_perc_h.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reactions_perc_h.to_csv('../data/lgbtq_2019_2020_reactions_perc_h.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plots showing for each type of sentiment, what's the split by reaction type - first by % then by absolute numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plotly.subplots import make_subplots\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "fig = make_subplots(rows=1, cols=1)\n",
    "fig.add_bar(x=reactions_perc_h.Date, y=reactions_perc_h.Positive_nlikes, name=\"% Likes\", row=1, col=1)\n",
    "fig.add_bar(x=reactions_perc_h.Date, y=reactions_perc_h.Positive_nreplies, name=\"% Replies\", row=1, col=1)\n",
    "fig.add_bar(x=reactions_perc_h.Date, y=reactions_perc_h.Positive_nretweets, name=\"% Retweets\", row=1, col=1)\n",
    "fig.update_layout(barmode=\"relative\",showlegend=True,title=\"Reactions classification for positive tweets\",\n",
    "                 yaxis_title=\"% of reactions\", xaxis_title=\"Time\")\n",
    "fig.show()\n",
    "\n",
    "fig = make_subplots(rows=1, cols=1)\n",
    "fig.add_bar(x=reactions_perc_h.Date, y=reactions_perc_h.Negative_nlikes, name=\"% Likes\", row=1, col=1)\n",
    "fig.add_bar(x=reactions_perc_h.Date, y=reactions_perc_h.Negative_nreplies, name=\"% Replies\", row=1, col=1)\n",
    "fig.add_bar(x=reactions_perc_h.Date, y=reactions_perc_h.Negative_nretweets, name=\"% Retweets\", row=1, col=1)\n",
    "fig.update_layout(barmode=\"relative\",showlegend=True,title=\"Reactions classification for negative tweets\",\n",
    "                 yaxis_title=\"% of reactions\", xaxis_title=\"Time\")\n",
    "fig.show()\n",
    "\n",
    "fig = make_subplots(rows=1, cols=1)\n",
    "fig.add_bar(x=reactions_perc_h.Date, y=reactions_perc_h.Neutral_nlikes, name=\"% Likes\", row=1, col=1)\n",
    "fig.add_bar(x=reactions_perc_h.Date, y=reactions_perc_h.Neutral_nreplies, name=\"% Replies\", row=1, col=1)\n",
    "fig.add_bar(x=reactions_perc_h.Date, y=reactions_perc_h.Neutral_nretweets, name=\"% Retweets\", row=1, col=1)\n",
    "fig.update_layout(barmode=\"relative\",showlegend=True,title=\"Reactions classification for neutral tweets\",\n",
    "                 yaxis_title=\"% of reactions\", xaxis_title=\"Time\")\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plotly.subplots import make_subplots\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "fig = make_subplots(rows=1, cols=1)\n",
    "fig.add_bar(x=reactions_hor.Date, y=reactions_hor.Positive_nlikes, name=\"Likes\", row=1, col=1)\n",
    "fig.add_bar(x=reactions_hor.Date, y=reactions_hor.Positive_nreplies, name=\"Replies\", row=1, col=1)\n",
    "fig.add_bar(x=reactions_hor.Date, y=reactions_hor.Positive_nretweets, name=\"Retweets\", row=1, col=1)\n",
    "fig.update_layout(barmode=\"relative\",showlegend=True,title=\"Reactions classification for positive tweets\",\n",
    "                 yaxis_title=\"Number of reactions\", xaxis_title=\"Time\")\n",
    "fig.show()\n",
    "\n",
    "fig = make_subplots(rows=1, cols=1)\n",
    "fig.add_bar(x=reactions_hor.Date, y=reactions_hor.Negative_nlikes, name=\"Likes\", row=1, col=1)\n",
    "fig.add_bar(x=reactions_hor.Date, y=reactions_hor.Negative_nreplies, name=\"Replies\", row=1, col=1)\n",
    "fig.add_bar(x=reactions_hor.Date, y=reactions_hor.Negative_nretweets, name=\"Retweets\", row=1, col=1)\n",
    "fig.update_layout(barmode=\"relative\",showlegend=True,title=\"Reactions classification for negative tweets\",\n",
    "                 yaxis_title=\"Number of reactions\", xaxis_title=\"Time\")\n",
    "fig.show()\n",
    "\n",
    "fig = make_subplots(rows=1, cols=1)\n",
    "fig.add_bar(x=reactions_hor.Date, y=reactions_hor.Neutral_nlikes, name=\"Likes\", row=1, col=1)\n",
    "fig.add_bar(x=reactions_hor.Date, y=reactions_hor.Neutral_nreplies, name=\"Replies\", row=1, col=1)\n",
    "fig.add_bar(x=reactions_hor.Date, y=reactions_hor.Neutral_nretweets, name=\"Retweets\", row=1, col=1)\n",
    "fig.update_layout(barmode=\"relative\",showlegend=True,title=\"Reactions classification for neutral tweets\",\n",
    "                 yaxis_title=\"Number of reactions\", xaxis_title=\"Time\")\n",
    "fig.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
